{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDERTm3_ah53"
   },
   "source": [
    "Resources Used\n",
    "- wget.download('https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py')\n",
    "- Setup https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97EInejsah6J"
   },
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9Oh9DIRaueS"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y -qq protobuf-compiler python-pil python-lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "boW3j7poauZ_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!git clone --quiet https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ktzfyd9XaJ_C"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vRP9vajYauXh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/models/research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28420,
     "status": "ok",
     "timestamp": 1620635348704,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "OR_js8KRd0YW",
    "outputId": "6466600c-0caa-4b6a-93a3-8a5c7c577ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zt9ChK9KauOk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1620635365583,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "7xei7n-Mah6M"
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\workspace'\n",
    "SCRIPTS_PATH = 'C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\scripts'\n",
    "APIMODEL_PATH = 'C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\models'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'\\\\annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'\\\\images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'\\\\models'\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'\\\\pre-trained-models'\n",
    "CONFIG_PATH = MODEL_PATH+'\\\\my_ssd_mobnet\\\\pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'\\\\my_ssd_mobnet\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RO1VFdkxPxI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkG00-Fsah6N"
   },
   "source": [
    "# 1. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1140,
     "status": "ok",
     "timestamp": 1620635369613,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "RMLS9HFmah6O"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'A', 'id':1}, {'name':'B', 'id':2},{'name':'C', 'id':3},{'name':'D', 'id':4},{'name':'E', 'id':5},{'name':'F', 'id':6},{'name':'G', 'id':7},{'name':'H', 'id':8},{'name':'I', 'id':9},{'name':'K', 'id':10},\n",
    "         {'name':'L', 'id':11},{'name':'M', 'id':12},{'name':'N', 'id':13},{'name':'O', 'id':14},{'name':'P', 'id':15},{'name':'Q', 'id':16},{'name':'R', 'id':17},{'name':'S', 'id':18},{'name':'T', 'id':19},{'name':'U', 'id':20},{'name':'V', 'id':21},{'name':'W', 'id':22},{'name':'X', 'id':23},{'name':'Y', 'id':24}]\n",
    "\n",
    "# with open(ANNOTATION_PATH + '\\label_map.pbtxt', 'w') as f:\n",
    "#     for label in labels:\n",
    "#         f.write('item { \\n')\n",
    "#         f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "#         f.write('\\tid:{}\\n'.format(label['id']))\n",
    "#         f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wXb_KESah6Q"
   },
   "source": [
    "# 2. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4827,
     "status": "ok",
     "timestamp": 1620508783253,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "met81XxqheB-",
    "outputId": "17cb9124-8ecd-49b0-e176-60daae0fd9ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5keIkQkja-h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4690,
     "status": "ok",
     "timestamp": 1620508792055,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "1weT8rgJhq8B",
    "outputId": "9b22fbfd-d952-4e85-b7c1-e586385b364b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-models-official in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.19.5)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.15.0)\n",
      "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.4.1)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.5.12)\n",
      "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.21.0)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.1.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (3.2.2)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.0.2)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.1.3)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.12.8)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.5.2.52)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (5.4.1)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.5.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.6)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (8.0.0)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (5.4.8)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (7.1.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.29.22)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.4.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.1.95)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.12.0)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.0.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.12.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.36.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (3.12.4)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.3.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.32.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (2.4.1)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (2.10.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.0.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2020.12.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.41.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.24.3)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official) (1.0.3)\n",
      "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official) (0.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->tf-models-official) (2018.9)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (1.3.1)\n",
      "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->tf-models-official) (56.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official) (0.17.4)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.0.4)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.26.3)\n",
      "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.28.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official) (2.7.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.6)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official) (0.22.2.post1)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.29.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.16.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.3.3)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (5.1.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (20.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (0.4.4)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (2.10)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (20.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official) (3.4.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (3.10.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icN32AVQSa_R"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PYTHONPATH'] += \":/content/models/research:/content/models/research/slim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5704,
     "status": "ok",
     "timestamp": 1620508899803,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "QZNafxdRhO4U",
    "outputId": "b819877c-85db-401e-a0a5-8c9d7f4b6949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-08 21:21:37.324457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "!python /content/models/research/object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bj5xKvzphTq7"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y -qq protobuf-compiler python-pil python-lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqZQO1eRf47R"
   },
   "outputs": [],
   "source": [
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49YJDwXzfL2X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONPATH'] += \"/content/models/research\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRW4XSAqjtJV"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PYTHONPATH'] += \":/content/models/research:/content/models/research/slim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7464,
     "status": "ok",
     "timestamp": 1620507928604,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "QQ1Gv6qQah6R",
    "outputId": "cbd3e81e-9806-4d5a-cb59-ee8352387a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: C:\\Users\\Hemanth\\Downloads\\RealTimeObjectDetection\\Tensorflow\\workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: C:\\Users\\Hemanth\\Downloads\\RealTimeObjectDetection\\Tensorflow\\workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n",
    "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x{IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67tSY80Cah6T"
   },
   "source": [
    "# 3. Download TF Models Pretrained Models from Tensorflow Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3DYqBAeah6U",
    "outputId": "f142a4db-d311-491d-b061-1406c87b1714"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n"
     ]
    }
   ],
   "source": [
    "!cd Tensorflow && git clone https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSKo5JuDah6W"
   },
   "outputs": [],
   "source": [
    "#wget.download('http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz')\n",
    "#!mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz {PRETRAINED_MODEL_PATH}\n",
    "#!cd {PRETRAINED_MODEL_PATH} && tar -zxvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXT2_EzNah6X"
   },
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1620635384325,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "Ed9ASMowah6X"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzv0NIYXah6Y"
   },
   "outputs": [],
   "source": [
    "!mkdir {'/content/drive/MyDrive/RealTimeObjectDetection/Tensorflow/workspace/models/'+CUSTOM_MODEL_NAME}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56oKXT9Rne9E"
   },
   "outputs": [],
   "source": [
    "!cp {PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config'} {MODEL_PATH+'/'+CUSTOM_MODEL_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULNxEvweah6Z"
   },
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1620636276897,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "jtpQr0Viah6a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "roaDg8Qaah6b"
   },
   "outputs": [],
   "source": [
    "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1848,
     "status": "ok",
     "timestamp": 1620589094769,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "42MGxDCTlHxb",
    "outputId": "4ee862d1-3026-4082-d20c-f96272295a84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\workspace\\\\models/my_ssd_mobnet/pipeline.config'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qBLk13IRah6b"
   },
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1325,
     "status": "ok",
     "timestamp": 1620589212776,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "I4j2BS2dah6c",
    "outputId": "57d060fe-fd65-4131-ebad-bf23ba5dee8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 24\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 4e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.01\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.997\n",
       "         scale: true\n",
       "         epsilon: 0.001\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 4e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.01\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.997\n",
       "           scale: true\n",
       "           epsilon: 0.001\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.6\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 1e-08\n",
       "       iou_threshold: 0.6\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 4\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.08\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.9\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\workspace\\\\pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"detection\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\workspace\\\\annotations/label_map.pbtxt\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\workspace\\\\annotations/train.record\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\workspace\\\\annotations/label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\workspace\\\\annotations/test.record\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\workspace\\\\annotations/label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"C:\\\\Users\\\\Hemanth\\\\Downloads\\\\RealTimeObjectDetection\\\\Tensorflow\\\\workspace\\\\annotations/test.record\"\n",
       " }}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "G4Iirloiah6d"
   },
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UXnEFrzfah6e"
   },
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = 24\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/train.record']\n",
    "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FXpd_Fiuah6g"
   },
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RDCzxjlah6h"
   },
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6366,
     "status": "ok",
     "timestamp": 1620388090308,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "IXtt3PJDp-9O",
    "outputId": "576b1425-b434-4860-bd20-71b74dc71aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lvis\n",
      "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
      "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.22)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n",
      "Installing collected packages: lvis\n",
      "Successfully installed lvis-0.5.3\n"
     ]
    }
   ],
   "source": [
    "pip install lvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1807,
     "status": "ok",
     "timestamp": 1620387800639,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "9OGR2Ls7ah6h",
    "outputId": "0968a9d8-8769-4952-9bfb-6e027d200fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python C:\\Users\\Hemanth\\anaconda3\\Lib\\site-packages\\object_detection\\model_main_tf2.py --model_dir=C:\\Users\\Hemanth\\Downloads\\RealTimeObjectDetection\\Tensorflow\\workspace\\models\\my_ssd_mobnet --pipeline_config_path=C:\\Users\\Hemanth\\Downloads\\RealTimeObjectDetection\\Tensorflow\\workspace\\models/my_ssd_mobnet/pipeline.config --num_train_steps=5000\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"python {}\\\\model_main_tf2.py --model_dir={}\\\\{} --pipeline_config_path={}/{}/pipeline.config --num_train_steps=5000\"\"\".format(\"C:\\\\Users\\\\Hemanth\\\\anaconda3\\\\Lib\\\\site-packages\\\\object_detection\", MODEL_PATH,CUSTOM_MODEL_NAME,MODEL_PATH,CUSTOM_MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3338736,
     "status": "ok",
     "timestamp": 1620398527525,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "jrbj6pz8o-GP",
    "outputId": "7ca583b1-9ed6-407b-9ad2-b4b2371183ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python C:\\\\Users\\\\Hemanth\\\\Downloads\\\\models-master\\\\research\\\\object_detection\\\\model_main_tf2.py --model_dir=C:\\Users\\Hemanth\\Downloads\\RealTimeObjectDetection\\Tensorflow\\workspace/models/my_ssd_mobnet --pipeline_config_path=C:\\Users\\Hemanth\\Downloads\\RealTimeObjectDetection\\Tensorflow\\workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xBbfXQyah6i"
   },
   "source": [
    "# 7. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13283,
     "status": "ok",
     "timestamp": 1620635427549,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "dGqx9gso4uE7",
    "outputId": "47db050d-c886-4970-831b-dd0cd34fa264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package python-bs4.\n",
      "(Reading database ... 160706 files and directories currently installed.)\n",
      "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
      "Unpacking python-bs4 (4.6.0-1) ...\n",
      "Selecting previously unselected package python-pkg-resources.\n",
      "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
      "Unpacking python-pkg-resources (39.0.1-2) ...\n",
      "Selecting previously unselected package python-chardet.\n",
      "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
      "Unpacking python-chardet (3.0.4-1) ...\n",
      "Selecting previously unselected package python-six.\n",
      "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
      "Unpacking python-six (1.11.0-2) ...\n",
      "Selecting previously unselected package python-webencodings.\n",
      "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
      "Unpacking python-webencodings (0.5-2) ...\n",
      "Selecting previously unselected package python-html5lib.\n",
      "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
      "Unpacking python-html5lib (0.999999999-1) ...\n",
      "Selecting previously unselected package python-lxml:amd64.\n",
      "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.4_amd64.deb ...\n",
      "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
      "Selecting previously unselected package python-olefile.\n",
      "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
      "Unpacking python-olefile (0.45.1-1) ...\n",
      "Selecting previously unselected package python-pil:amd64.\n",
      "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.5_amd64.deb ...\n",
      "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
      "Setting up python-pkg-resources (39.0.1-2) ...\n",
      "Setting up python-six (1.11.0-2) ...\n",
      "Setting up python-bs4 (4.6.0-1) ...\n",
      "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
      "Setting up python-olefile (0.45.1-1) ...\n",
      "Setting up python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
      "Setting up python-webencodings (0.5-2) ...\n",
      "Setting up python-chardet (3.0.4-1) ...\n",
      "Setting up python-html5lib (0.999999999-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq protobuf-compiler python-pil python-lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 22817,
     "status": "ok",
     "timestamp": 1620636088814,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "gnqQv5Gs4vg1"
   },
   "outputs": [],
   "source": [
    "!git clone --quiet https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1133,
     "status": "ok",
     "timestamp": 1620636106988,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "dD-APpU_45NK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('models/research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1688,
     "status": "ok",
     "timestamp": 1620636110840,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "tAMK_9CS46TR"
   },
   "outputs": [],
   "source": [
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1425,
     "status": "ok",
     "timestamp": 1620636132974,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "KrHD4SpK5fLF"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PYTHONPATH'] += \":/content/models/research:/content/models/research/slim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5865,
     "status": "ok",
     "timestamp": 1620636140658,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "8kSYi5cP5iw2",
    "outputId": "bc9b12d5-084c-4365-890d-9b4133cfc7a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf_slim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
      "\r",
      "\u001b[K     |█                               | 10kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 20kB 9.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 30kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 40kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 51kB 5.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 61kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 71kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 81kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 92kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 102kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 112kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 122kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 133kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 143kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 153kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 163kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 174kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 184kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 194kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 204kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 215kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 225kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 235kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 245kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 256kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 266kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 276kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 286kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 296kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 307kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 317kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 327kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 337kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 348kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 358kB 6.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
      "Installing collected packages: tf-slim\n",
      "Successfully installed tf-slim-1.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 17895,
     "status": "ok",
     "timestamp": 1620636227008,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "fEvvhaKr5pD-",
    "outputId": "c7505d84-ade6-4a38-cb48-ea9f19e056f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-models-official\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/4a/23a08f8fd2747867ee223612e219eeb0d11c36116601d99b55ef3c72e707/tf_models_official-2.4.0-py2.py3-none-any.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 4.8MB/s \n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
      "\u001b[K     |████████████████████████████████| 706kB 25.9MB/s \n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/84/72ec52fbac4775c2a5bf0ee5573c922a0cac35eb841907edf56493a5e313/opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n",
      "\u001b[K     |████████████████████████████████| 38.2MB 97kB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.15.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.5.12)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.1.5)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.12.8)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.0.1)\n",
      "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.4.1)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 34.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.12.0)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.1.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (3.2.2)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 9.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.19.5)\n",
      "Collecting dataclasses\n",
      "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.29.22)\n",
      "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.21.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.0.2)\n",
      "Collecting seqeval\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 39.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.4.1)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 39.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (7.1.2)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (5.4.8)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official) (2.7.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.23.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.24.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2020.12.5)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.0.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.41.1)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->tf-models-official) (2018.9)\n",
      "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.28.1)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.26.3)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.0.4)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.17.4)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim>=1.1.0->tf-models-official) (0.12.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.16.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.29.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (20.3.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.3.3)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (5.1.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (3.12.4)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (2.4.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (2.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (1.32.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.36.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official) (0.3.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official) (4.7.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (1.3.1)\n",
      "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official) (0.4.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official) (1.0.3)\n",
      "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->tf-models-official) (56.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official) (0.22.2.post1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (2.10)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (20.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (1.53.0)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official) (3.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (3.10.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official) (3.1.0)\n",
      "Building wheels for collected packages: py-cpuinfo, seqeval\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=db5db9b2e832beabc7dd9feb4f6c356e516c2f9e09d074942661325f2a47ea65\n",
      "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=d1acc3ca281f1e8e2ae33e6bce1ca8cec9bb7651c31e397f832218dd0956beef\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
      "Successfully built py-cpuinfo seqeval\n",
      "Installing collected packages: tensorflow-addons, opencv-python-headless, tensorflow-model-optimization, py-cpuinfo, dataclasses, seqeval, pyyaml, sentencepiece, tf-models-official\n",
      "  Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed dataclasses-0.6 opencv-python-headless-4.5.2.52 py-cpuinfo-8.0.0 pyyaml-5.4.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorflow-addons-0.12.1 tensorflow-model-optimization-0.5.0 tf-models-official-2.4.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "yaml"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4938,
     "status": "ok",
     "timestamp": 1620636234410,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "PpUhy6R65o4Q",
    "outputId": "4676ee2b-ac91-4c7e-c5ec-4c547ad227b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-10 08:43:52.200794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1694,
     "status": "ok",
     "timestamp": 1620636240750,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "Xip96065ah6j"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 3553,
     "status": "ok",
     "timestamp": 1620636307850,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "DxyldpVfah6k"
   },
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-6')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kq2iwr0Bah6l"
   },
   "source": [
    "# 8. Detect in Real-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1620636327306,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "ngLY4X7tah6n"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 1329,
     "status": "ok",
     "timestamp": 1620636331908,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "Mz9uZd8Sah6p"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "O_BApCNPah6r"
   },
   "outputs": [],
   "source": [
    "# Setup capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1158,
     "status": "ok",
     "timestamp": 1620636337466,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "AB_Hbd4XbXSQ"
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from IPython.display import display, Javascript, Image\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode, b64encode\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import io\n",
    "import html\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1620636365071,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "IEnJVmx4u2Rj"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'myfile.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8c90a6f04865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"myfile.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'myfile.txt'"
     ]
    }
   ],
   "source": [
    "f = open(\"myfile.txt\", \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 1637,
     "status": "ok",
     "timestamp": 1620642242423,
     "user": {
      "displayName": "Harshith Sesham",
      "photoUrl": "",
      "userId": "05057888580377507907"
     },
     "user_tz": -330
    },
    "id": "ZRU25_0iaLBo",
    "outputId": "7a306646-e874-44f2-b3fb-86aa697c3571"
   },
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"A set of functions that are used for visualization.\n",
    "These functions often receive an image, perform some visualization on the image.\n",
    "The functions do not return a value, instead they modify the image itself.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import collections\n",
    "# Set headless-friendly backend.\n",
    "import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n",
    "import matplotlib.pyplot as plt  # pylint: disable=g-import-not-at-top\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "import six\n",
    "from six.moves import range\n",
    "from six.moves import zip\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from object_detection.core import keypoint_ops\n",
    "from object_detection.core import standard_fields as fields\n",
    "from object_detection.utils import shape_utils\n",
    "final_label=None\n",
    "_TITLE_LEFT_MARGIN = 10\n",
    "_TITLE_TOP_MARGIN = 10\n",
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
    "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
    "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]\n",
    "\n",
    "\n",
    "def _get_multiplier_for_color_randomness():\n",
    "  \"\"\"Returns a multiplier to get semi-random colors from successive indices.\n",
    "  This function computes a prime number, p, in the range [2, 17] that:\n",
    "  - is closest to len(STANDARD_COLORS) / 10\n",
    "  - does not divide len(STANDARD_COLORS)\n",
    "  If no prime numbers in that range satisfy the constraints, p is returned as 1.\n",
    "  Once p is established, it can be used as a multiplier to select\n",
    "  non-consecutive colors from STANDARD_COLORS:\n",
    "  colors = [(p * i) % len(STANDARD_COLORS) for i in range(20)]\n",
    "  \"\"\"\n",
    "  num_colors = len(STANDARD_COLORS)\n",
    "  prime_candidates = [5, 7, 11, 13, 17]\n",
    "\n",
    "  # Remove all prime candidates that divide the number of colors.\n",
    "  prime_candidates = [p for p in prime_candidates if num_colors % p]\n",
    "  if not prime_candidates:\n",
    "    return 1\n",
    "\n",
    "  # Return the closest prime number to num_colors / 10.\n",
    "  abs_distance = [np.abs(num_colors / 10. - p) for p in prime_candidates]\n",
    "  num_candidates = len(abs_distance)\n",
    "  inds = [i for _, i in sorted(zip(abs_distance, range(num_candidates)))]\n",
    "  return prime_candidates[inds[0]]\n",
    "\n",
    "\n",
    "def save_image_array_as_png(image, output_path):\n",
    "  \"\"\"Saves an image (represented as a numpy array) to PNG.\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "    output_path: path to which image should be written.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  with tf.gfile.Open(output_path, 'w') as fid:\n",
    "    image_pil.save(fid, 'PNG')\n",
    "\n",
    "\n",
    "def encode_image_array_as_png_str(image):\n",
    "  \"\"\"Encodes a numpy array into a PNG string.\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "  Returns:\n",
    "    PNG encoded image string.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image))\n",
    "  output = six.BytesIO()\n",
    "  image_pil.save(output, format='PNG')\n",
    "  png_string = output.getvalue()\n",
    "  output.close()\n",
    "  return png_string\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image_array(image,\n",
    "                                     ymin,\n",
    "                                     xmin,\n",
    "                                     ymax,\n",
    "                                     xmax,\n",
    "                                     color='red',\n",
    "                                     thickness=4,\n",
    "                                     display_str_list=(),\n",
    "                                     use_normalized_coordinates=True):\n",
    "  \"\"\"Adds a bounding box to an image (numpy array).\n",
    "  Bounding box coordinates can be specified in either absolute (pixel) or\n",
    "  normalized coordinates by setting the use_normalized_coordinates argument.\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "    ymin: ymin of bounding box.\n",
    "    xmin: xmin of bounding box.\n",
    "    ymax: ymax of bounding box.\n",
    "    xmax: xmax of bounding box.\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: list of strings to display in box\n",
    "                      (each to be shown on its own line).\n",
    "    use_normalized_coordinates: If True (default), treat coordinates\n",
    "      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
    "      coordinates as absolute.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
    "                             thickness, display_str_list,\n",
    "                             use_normalized_coordinates)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color='red',\n",
    "                               thickness=4,\n",
    "                               display_str_list=(),\n",
    "                               use_normalized_coordinates=True):\n",
    "  \"\"\"Adds a bounding box to an image.\n",
    "  Bounding box coordinates can be specified in either absolute (pixel) or\n",
    "  normalized coordinates by setting the use_normalized_coordinates argument.\n",
    "  Each string in display_str_list is displayed on a separate line above the\n",
    "  bounding box in black text on a rectangle filled with the input 'color'.\n",
    "  If the top of the bounding box extends to the edge of the image, the strings\n",
    "  are displayed below the bounding box.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    ymin: ymin of bounding box.\n",
    "    xmin: xmin of bounding box.\n",
    "    ymax: ymax of bounding box.\n",
    "    xmax: xmax of bounding box.\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: list of strings to display in box\n",
    "                      (each to be shown on its own line).\n",
    "    use_normalized_coordinates: If True (default), treat coordinates\n",
    "      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
    "      coordinates as absolute.\n",
    "  \"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  if use_normalized_coordinates:\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "  else:\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "  if thickness > 0:\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "               (left, top)],\n",
    "              width=thickness,\n",
    "              fill=color)\n",
    "  try:\n",
    "    font = ImageFont.truetype('arial.ttf', 24)\n",
    "  except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = bottom + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle(\n",
    "        [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                          text_bottom)],\n",
    "        fill=color)\n",
    "    draw.text(\n",
    "        (left + margin, text_bottom - text_height - margin),\n",
    "        display_str,\n",
    "        fill='black',\n",
    "        font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_on_image_array(image,\n",
    "                                       boxes,\n",
    "                                       color='red',\n",
    "                                       thickness=4,\n",
    "                                       display_str_list_list=()):\n",
    "  \"\"\"Draws bounding boxes on image (numpy array).\n",
    "  Args:\n",
    "    image: a numpy array object.\n",
    "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
    "           The coordinates are in normalized format between [0, 1].\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list_list: list of list of strings.\n",
    "                           a list of strings for each bounding box.\n",
    "                           The reason to pass a list of strings for a\n",
    "                           bounding box is that it might contain\n",
    "                           multiple labels.\n",
    "  Raises:\n",
    "    ValueError: if boxes is not a [N, 4] array\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(image)\n",
    "  draw_bounding_boxes_on_image(image_pil, boxes, color, thickness,\n",
    "                               display_str_list_list)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_on_image(image,\n",
    "                                 boxes,\n",
    "                                 color='red',\n",
    "                                 thickness=4,\n",
    "                                 display_str_list_list=()):\n",
    "  \"\"\"Draws bounding boxes on image.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
    "           The coordinates are in normalized format between [0, 1].\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list_list: list of list of strings.\n",
    "                           a list of strings for each bounding box.\n",
    "                           The reason to pass a list of strings for a\n",
    "                           bounding box is that it might contain\n",
    "                           multiple labels.\n",
    "  Raises:\n",
    "    ValueError: if boxes is not a [N, 4] array\n",
    "  \"\"\"\n",
    "  boxes_shape = boxes.shape\n",
    "  if not boxes_shape:\n",
    "    return\n",
    "  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
    "    raise ValueError('Input must be of size [N, 4]')\n",
    "  for i in range(boxes_shape[0]):\n",
    "    display_str_list = ()\n",
    "    if display_str_list_list:\n",
    "      display_str_list = display_str_list_list[i]\n",
    "    draw_bounding_box_on_image(image, boxes[i, 0], boxes[i, 1], boxes[i, 2],\n",
    "                               boxes[i, 3], color, thickness, display_str_list)\n",
    "\n",
    "\n",
    "def create_visualization_fn(category_index,\n",
    "                            include_masks=False,\n",
    "                            include_keypoints=False,\n",
    "                            include_keypoint_scores=False,\n",
    "                            include_track_ids=False,\n",
    "                            **kwargs):\n",
    "  \"\"\"Constructs a visualization function that can be wrapped in a py_func.\n",
    "  py_funcs only accept positional arguments. This function returns a suitable\n",
    "  function with the correct positional argument mapping. The positional\n",
    "  arguments in order are:\n",
    "  0: image\n",
    "  1: boxes\n",
    "  2: classes\n",
    "  3: scores\n",
    "  [4]: masks (optional)\n",
    "  [4-5]: keypoints (optional)\n",
    "  [4-6]: keypoint_scores (optional)\n",
    "  [4-7]: track_ids (optional)\n",
    "  -- Example 1 --\n",
    "  vis_only_masks_fn = create_visualization_fn(category_index,\n",
    "    include_masks=True, include_keypoints=False, include_track_ids=False,\n",
    "    **kwargs)\n",
    "  image = tf.py_func(vis_only_masks_fn,\n",
    "                     inp=[image, boxes, classes, scores, masks],\n",
    "                     Tout=tf.uint8)\n",
    "  -- Example 2 --\n",
    "  vis_masks_and_track_ids_fn = create_visualization_fn(category_index,\n",
    "    include_masks=True, include_keypoints=False, include_track_ids=True,\n",
    "    **kwargs)\n",
    "  image = tf.py_func(vis_masks_and_track_ids_fn,\n",
    "                     inp=[image, boxes, classes, scores, masks, track_ids],\n",
    "                     Tout=tf.uint8)\n",
    "  Args:\n",
    "    category_index: a dict that maps integer ids to category dicts. e.g.\n",
    "      {1: {1: 'dog'}, 2: {2: 'cat'}, ...}\n",
    "    include_masks: Whether masks should be expected as a positional argument in\n",
    "      the returned function.\n",
    "    include_keypoints: Whether keypoints should be expected as a positional\n",
    "      argument in the returned function.\n",
    "    include_keypoint_scores: Whether keypoint scores should be expected as a\n",
    "      positional argument in the returned function.\n",
    "    include_track_ids: Whether track ids should be expected as a positional\n",
    "      argument in the returned function.\n",
    "    **kwargs: Additional kwargs that will be passed to\n",
    "      visualize_boxes_and_labels_on_image_array.\n",
    "  Returns:\n",
    "    Returns a function that only takes tensors as positional arguments.\n",
    "  \"\"\"\n",
    "\n",
    "  def visualization_py_func_fn(*args):\n",
    "    \"\"\"Visualization function that can be wrapped in a tf.py_func.\n",
    "    Args:\n",
    "      *args: First 4 positional arguments must be:\n",
    "        image - uint8 numpy array with shape (img_height, img_width, 3).\n",
    "        boxes - a numpy array of shape [N, 4].\n",
    "        classes - a numpy array of shape [N].\n",
    "        scores - a numpy array of shape [N] or None.\n",
    "        -- Optional positional arguments --\n",
    "        instance_masks - a numpy array of shape [N, image_height, image_width].\n",
    "        keypoints - a numpy array of shape [N, num_keypoints, 2].\n",
    "        keypoint_scores - a numpy array of shape [N, num_keypoints].\n",
    "        track_ids - a numpy array of shape [N] with unique track ids.\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3) with overlaid\n",
    "      boxes.\n",
    "    \"\"\"\n",
    "    image = args[0]\n",
    "    boxes = args[1]\n",
    "    classes = args[2]\n",
    "    scores = args[3]\n",
    "    masks = keypoints = keypoint_scores = track_ids = None\n",
    "    pos_arg_ptr = 4  # Positional argument for first optional tensor (masks).\n",
    "    if include_masks:\n",
    "      masks = args[pos_arg_ptr]\n",
    "      pos_arg_ptr += 1\n",
    "    if include_keypoints:\n",
    "      keypoints = args[pos_arg_ptr]\n",
    "      pos_arg_ptr += 1\n",
    "    if include_keypoint_scores:\n",
    "      keypoint_scores = args[pos_arg_ptr]\n",
    "      pos_arg_ptr += 1\n",
    "    if include_track_ids:\n",
    "      track_ids = args[pos_arg_ptr]\n",
    "\n",
    "    return visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        boxes,\n",
    "        classes,\n",
    "        scores,\n",
    "        category_index=category_index,\n",
    "        instance_masks=masks,\n",
    "        keypoints=keypoints,\n",
    "        keypoint_scores=keypoint_scores,\n",
    "        track_ids=track_ids,\n",
    "        **kwargs)\n",
    "  return visualization_py_func_fn\n",
    "\n",
    "\n",
    "def draw_heatmaps_on_image(image, heatmaps):\n",
    "  \"\"\"Draws heatmaps on an image.\n",
    "  The heatmaps are handled channel by channel and different colors are used to\n",
    "  paint different heatmap channels.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    heatmaps: a numpy array with shape [image_height, image_width, channel].\n",
    "      Note that the image_height and image_width should match the size of input\n",
    "      image.\n",
    "  \"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  channel = heatmaps.shape[2]\n",
    "  for c in range(channel):\n",
    "    heatmap = heatmaps[:, :, c] * 255\n",
    "    heatmap = heatmap.astype('uint8')\n",
    "    bitmap = Image.fromarray(heatmap, 'L')\n",
    "    bitmap.convert('1')\n",
    "    draw.bitmap(\n",
    "        xy=[(0, 0)],\n",
    "        bitmap=bitmap,\n",
    "        fill=STANDARD_COLORS[c])\n",
    "\n",
    "\n",
    "def draw_heatmaps_on_image_array(image, heatmaps):\n",
    "  \"\"\"Overlays heatmaps to an image (numpy array).\n",
    "  The function overlays the heatmaps on top of image. The heatmap values will be\n",
    "  painted with different colors depending on the channels. Similar to\n",
    "  \"draw_heatmaps_on_image_array\" function except the inputs are numpy arrays.\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "    heatmaps: a numpy array with shape [height, width, channel].\n",
    "  Returns:\n",
    "    An uint8 numpy array representing the input image painted with heatmap\n",
    "    colors.\n",
    "  \"\"\"\n",
    "  if not isinstance(image, np.ndarray):\n",
    "    image = image.numpy()\n",
    "  if not isinstance(heatmaps, np.ndarray):\n",
    "    heatmaps = heatmaps.numpy()\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_heatmaps_on_image(image_pil, heatmaps)\n",
    "  return np.array(image_pil)\n",
    "\n",
    "\n",
    "def draw_heatmaps_on_image_tensors(images,\n",
    "                                   heatmaps,\n",
    "                                   apply_sigmoid=False):\n",
    "  \"\"\"Draws heatmaps on batch of image tensors.\n",
    "  Args:\n",
    "    images: A 4D uint8 image tensor of shape [N, H, W, C]. If C > 3, additional\n",
    "      channels will be ignored. If C = 1, then we convert the images to RGB\n",
    "      images.\n",
    "    heatmaps: [N, h, w, channel] float32 tensor of heatmaps. Note that the\n",
    "      heatmaps will be resized to match the input image size before overlaying\n",
    "      the heatmaps with input images. Theoretically the heatmap height width\n",
    "      should have the same aspect ratio as the input image to avoid potential\n",
    "      misalignment introduced by the image resize.\n",
    "    apply_sigmoid: Whether to apply a sigmoid layer on top of the heatmaps. If\n",
    "      the heatmaps come directly from the prediction logits, then we should\n",
    "      apply the sigmoid layer to make sure the values are in between [0.0, 1.0].\n",
    "  Returns:\n",
    "    4D image tensor of type uint8, with heatmaps overlaid on top.\n",
    "  \"\"\"\n",
    "  # Additional channels are being ignored.\n",
    "  if images.shape[3] > 3:\n",
    "    images = images[:, :, :, 0:3]\n",
    "  elif images.shape[3] == 1:\n",
    "    images = tf.image.grayscale_to_rgb(images)\n",
    "\n",
    "  _, height, width, _ = shape_utils.combined_static_and_dynamic_shape(images)\n",
    "  if apply_sigmoid:\n",
    "    heatmaps = tf.math.sigmoid(heatmaps)\n",
    "  resized_heatmaps = tf.image.resize(heatmaps, size=[height, width])\n",
    "\n",
    "  elems = [images, resized_heatmaps]\n",
    "\n",
    "  def draw_heatmaps(image_and_heatmaps):\n",
    "    \"\"\"Draws heatmaps on image.\"\"\"\n",
    "    image_with_heatmaps = tf.py_function(\n",
    "        draw_heatmaps_on_image_array,\n",
    "        image_and_heatmaps,\n",
    "        tf.uint8)\n",
    "    return image_with_heatmaps\n",
    "  images = tf.map_fn(draw_heatmaps, elems, dtype=tf.uint8, back_prop=False)\n",
    "  return images\n",
    "\n",
    "\n",
    "def _resize_original_image(image, image_shape):\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  image = tf.image.resize_images(\n",
    "      image,\n",
    "      image_shape,\n",
    "      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
    "      align_corners=True)\n",
    "  return tf.cast(tf.squeeze(image, 0), tf.uint8)\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_on_image_tensors(images,\n",
    "                                         boxes,\n",
    "                                         classes,\n",
    "                                         scores,\n",
    "                                         category_index,\n",
    "                                         original_image_spatial_shape=None,\n",
    "                                         true_image_shape=None,\n",
    "                                         instance_masks=None,\n",
    "                                         keypoints=None,\n",
    "                                         keypoint_scores=None,\n",
    "                                         keypoint_edges=None,\n",
    "                                         track_ids=None,\n",
    "                                         max_boxes_to_draw=20,\n",
    "                                         min_score_thresh=0.2,\n",
    "                                         use_normalized_coordinates=True):\n",
    "  \"\"\"Draws bounding boxes, masks, and keypoints on batch of image tensors.\n",
    "  Args:\n",
    "    images: A 4D uint8 image tensor of shape [N, H, W, C]. If C > 3, additional\n",
    "      channels will be ignored. If C = 1, then we convert the images to RGB\n",
    "      images.\n",
    "    boxes: [N, max_detections, 4] float32 tensor of detection boxes.\n",
    "    classes: [N, max_detections] int tensor of detection classes. Note that\n",
    "      classes are 1-indexed.\n",
    "    scores: [N, max_detections] float32 tensor of detection scores.\n",
    "    category_index: a dict that maps integer ids to category dicts. e.g.\n",
    "      {1: {1: 'dog'}, 2: {2: 'cat'}, ...}\n",
    "    original_image_spatial_shape: [N, 2] tensor containing the spatial size of\n",
    "      the original image.\n",
    "    true_image_shape: [N, 3] tensor containing the spatial size of unpadded\n",
    "      original_image.\n",
    "    instance_masks: A 4D uint8 tensor of shape [N, max_detection, H, W] with\n",
    "      instance masks.\n",
    "    keypoints: A 4D float32 tensor of shape [N, max_detection, num_keypoints, 2]\n",
    "      with keypoints.\n",
    "    keypoint_scores: A 3D float32 tensor of shape [N, max_detection,\n",
    "      num_keypoints] with keypoint scores.\n",
    "    keypoint_edges: A list of tuples with keypoint indices that specify which\n",
    "      keypoints should be connected by an edge, e.g. [(0, 1), (2, 4)] draws\n",
    "      edges from keypoint 0 to 1 and from keypoint 2 to 4.\n",
    "    track_ids: [N, max_detections] int32 tensor of unique tracks ids (i.e.\n",
    "      instance ids for each object). If provided, the color-coding of boxes is\n",
    "      dictated by these ids, and not classes.\n",
    "    max_boxes_to_draw: Maximum number of boxes to draw on an image. Default 20.\n",
    "    min_score_thresh: Minimum score threshold for visualization. Default 0.2.\n",
    "    use_normalized_coordinates: Whether to assume boxes and kepoints are in\n",
    "      normalized coordinates (as opposed to absolute coordiantes).\n",
    "      Default is True.\n",
    "  Returns:\n",
    "    4D image tensor of type uint8, with boxes drawn on top.\n",
    "  \"\"\"\n",
    "  # Additional channels are being ignored.\n",
    "  if images.shape[3] > 3:\n",
    "    images = images[:, :, :, 0:3]\n",
    "  elif images.shape[3] == 1:\n",
    "    images = tf.image.grayscale_to_rgb(images)\n",
    "  visualization_keyword_args = {\n",
    "      'use_normalized_coordinates': use_normalized_coordinates,\n",
    "      'max_boxes_to_draw': max_boxes_to_draw,\n",
    "      'min_score_thresh': min_score_thresh,\n",
    "      'agnostic_mode': False,\n",
    "      'line_thickness': 4,\n",
    "      'keypoint_edges': keypoint_edges\n",
    "  }\n",
    "  if true_image_shape is None:\n",
    "    true_shapes = tf.constant(-1, shape=[images.shape.as_list()[0], 3])\n",
    "  else:\n",
    "    true_shapes = true_image_shape\n",
    "  if original_image_spatial_shape is None:\n",
    "    original_shapes = tf.constant(-1, shape=[images.shape.as_list()[0], 2])\n",
    "  else:\n",
    "    original_shapes = original_image_spatial_shape\n",
    "\n",
    "  visualize_boxes_fn = create_visualization_fn(\n",
    "      category_index,\n",
    "      include_masks=instance_masks is not None,\n",
    "      include_keypoints=keypoints is not None,\n",
    "      include_keypoint_scores=keypoint_scores is not None,\n",
    "      include_track_ids=track_ids is not None,\n",
    "      **visualization_keyword_args)\n",
    "\n",
    "  elems = [true_shapes, original_shapes, images, boxes, classes, scores]\n",
    "  if instance_masks is not None:\n",
    "    elems.append(instance_masks)\n",
    "  if keypoints is not None:\n",
    "    elems.append(keypoints)\n",
    "  if keypoint_scores is not None:\n",
    "    elems.append(keypoint_scores)\n",
    "  if track_ids is not None:\n",
    "    elems.append(track_ids)\n",
    "\n",
    "  def draw_boxes(image_and_detections):\n",
    "    \"\"\"Draws boxes on image.\"\"\"\n",
    "    true_shape = image_and_detections[0]\n",
    "    original_shape = image_and_detections[1]\n",
    "    if true_image_shape is not None:\n",
    "      image = shape_utils.pad_or_clip_nd(image_and_detections[2],\n",
    "                                         [true_shape[0], true_shape[1], 3])\n",
    "    if original_image_spatial_shape is not None:\n",
    "      image_and_detections[2] = _resize_original_image(image, original_shape)\n",
    "\n",
    "    image_with_boxes = tf.py_func(visualize_boxes_fn, image_and_detections[2:],\n",
    "                                  tf.uint8)\n",
    "    return image_with_boxes\n",
    "\n",
    "  images = tf.map_fn(draw_boxes, elems, dtype=tf.uint8, back_prop=False)\n",
    "  return images\n",
    "\n",
    "\n",
    "def draw_side_by_side_evaluation_image(eval_dict,\n",
    "                                       category_index,\n",
    "                                       max_boxes_to_draw=20,\n",
    "                                       min_score_thresh=0.2,\n",
    "                                       use_normalized_coordinates=True,\n",
    "                                       keypoint_edges=None):\n",
    "  \"\"\"Creates a side-by-side image with detections and groundtruth.\n",
    "  Bounding boxes (and instance masks, if available) are visualized on both\n",
    "  subimages.\n",
    "  Args:\n",
    "    eval_dict: The evaluation dictionary returned by\n",
    "      eval_util.result_dict_for_batched_example() or\n",
    "      eval_util.result_dict_for_single_example().\n",
    "    category_index: A category index (dictionary) produced from a labelmap.\n",
    "    max_boxes_to_draw: The maximum number of boxes to draw for detections.\n",
    "    min_score_thresh: The minimum score threshold for showing detections.\n",
    "    use_normalized_coordinates: Whether to assume boxes and keypoints are in\n",
    "      normalized coordinates (as opposed to absolute coordinates).\n",
    "      Default is True.\n",
    "    keypoint_edges: A list of tuples with keypoint indices that specify which\n",
    "      keypoints should be connected by an edge, e.g. [(0, 1), (2, 4)] draws\n",
    "      edges from keypoint 0 to 1 and from keypoint 2 to 4.\n",
    "  Returns:\n",
    "    A list of [1, H, 2 * W, C] uint8 tensor. The subimage on the left\n",
    "      corresponds to detections, while the subimage on the right corresponds to\n",
    "      groundtruth.\n",
    "  \"\"\"\n",
    "  detection_fields = fields.DetectionResultFields()\n",
    "  input_data_fields = fields.InputDataFields()\n",
    "\n",
    "  images_with_detections_list = []\n",
    "\n",
    "  # Add the batch dimension if the eval_dict is for single example.\n",
    "  if len(eval_dict[detection_fields.detection_classes].shape) == 1:\n",
    "    for key in eval_dict:\n",
    "      if (key != input_data_fields.original_image and\n",
    "          key != input_data_fields.image_additional_channels):\n",
    "        eval_dict[key] = tf.expand_dims(eval_dict[key], 0)\n",
    "\n",
    "  num_gt_boxes = [-1] * eval_dict[input_data_fields.original_image].shape[0]\n",
    "  if input_data_fields.num_groundtruth_boxes in eval_dict:\n",
    "    num_gt_boxes = tf.cast(eval_dict[input_data_fields.num_groundtruth_boxes],\n",
    "                           tf.int32)\n",
    "  for indx in range(eval_dict[input_data_fields.original_image].shape[0]):\n",
    "    instance_masks = None\n",
    "    if detection_fields.detection_masks in eval_dict:\n",
    "      instance_masks = tf.cast(\n",
    "          tf.expand_dims(\n",
    "              eval_dict[detection_fields.detection_masks][indx], axis=0),\n",
    "          tf.uint8)\n",
    "    keypoints = None\n",
    "    keypoint_scores = None\n",
    "    if detection_fields.detection_keypoints in eval_dict:\n",
    "      keypoints = tf.expand_dims(\n",
    "          eval_dict[detection_fields.detection_keypoints][indx], axis=0)\n",
    "      if detection_fields.detection_keypoint_scores in eval_dict:\n",
    "        keypoint_scores = tf.expand_dims(\n",
    "            eval_dict[detection_fields.detection_keypoint_scores][indx], axis=0)\n",
    "      else:\n",
    "        keypoint_scores = tf.expand_dims(tf.cast(\n",
    "            keypoint_ops.set_keypoint_visibilities(\n",
    "                eval_dict[detection_fields.detection_keypoints][indx]),\n",
    "            dtype=tf.float32), axis=0)\n",
    "\n",
    "    groundtruth_instance_masks = None\n",
    "    if input_data_fields.groundtruth_instance_masks in eval_dict:\n",
    "      groundtruth_instance_masks = tf.cast(\n",
    "          tf.expand_dims(\n",
    "              eval_dict[input_data_fields.groundtruth_instance_masks][indx],\n",
    "              axis=0), tf.uint8)\n",
    "    groundtruth_keypoints = None\n",
    "    groundtruth_keypoint_scores = None\n",
    "    gt_kpt_vis_fld = input_data_fields.groundtruth_keypoint_visibilities\n",
    "    if input_data_fields.groundtruth_keypoints in eval_dict:\n",
    "      groundtruth_keypoints = tf.expand_dims(\n",
    "          eval_dict[input_data_fields.groundtruth_keypoints][indx], axis=0)\n",
    "      if gt_kpt_vis_fld in eval_dict:\n",
    "        groundtruth_keypoint_scores = tf.expand_dims(\n",
    "            tf.cast(eval_dict[gt_kpt_vis_fld][indx], dtype=tf.float32), axis=0)\n",
    "      else:\n",
    "        groundtruth_keypoint_scores = tf.expand_dims(tf.cast(\n",
    "            keypoint_ops.set_keypoint_visibilities(\n",
    "                eval_dict[input_data_fields.groundtruth_keypoints][indx]),\n",
    "            dtype=tf.float32), axis=0)\n",
    "    images_with_detections = draw_bounding_boxes_on_image_tensors(\n",
    "        tf.expand_dims(\n",
    "            eval_dict[input_data_fields.original_image][indx], axis=0),\n",
    "        tf.expand_dims(\n",
    "            eval_dict[detection_fields.detection_boxes][indx], axis=0),\n",
    "        tf.expand_dims(\n",
    "            eval_dict[detection_fields.detection_classes][indx], axis=0),\n",
    "        tf.expand_dims(\n",
    "            eval_dict[detection_fields.detection_scores][indx], axis=0),\n",
    "        category_index,\n",
    "        original_image_spatial_shape=tf.expand_dims(\n",
    "            eval_dict[input_data_fields.original_image_spatial_shape][indx],\n",
    "            axis=0),\n",
    "        true_image_shape=tf.expand_dims(\n",
    "            eval_dict[input_data_fields.true_image_shape][indx], axis=0),\n",
    "        instance_masks=instance_masks,\n",
    "        keypoints=keypoints,\n",
    "        keypoint_scores=keypoint_scores,\n",
    "        keypoint_edges=keypoint_edges,\n",
    "        max_boxes_to_draw=max_boxes_to_draw,\n",
    "        min_score_thresh=min_score_thresh,\n",
    "        use_normalized_coordinates=use_normalized_coordinates)\n",
    "    num_gt_boxes_i = num_gt_boxes[indx]\n",
    "    images_with_groundtruth = draw_bounding_boxes_on_image_tensors(\n",
    "        tf.expand_dims(\n",
    "            eval_dict[input_data_fields.original_image][indx],\n",
    "            axis=0),\n",
    "        tf.expand_dims(\n",
    "            eval_dict[input_data_fields.groundtruth_boxes][indx]\n",
    "            [:num_gt_boxes_i],\n",
    "            axis=0),\n",
    "        tf.expand_dims(\n",
    "            eval_dict[input_data_fields.groundtruth_classes][indx]\n",
    "            [:num_gt_boxes_i],\n",
    "            axis=0),\n",
    "        tf.expand_dims(\n",
    "            tf.ones_like(\n",
    "                eval_dict[input_data_fields.groundtruth_classes][indx]\n",
    "                [:num_gt_boxes_i],\n",
    "                dtype=tf.float32),\n",
    "            axis=0),\n",
    "        category_index,\n",
    "        original_image_spatial_shape=tf.expand_dims(\n",
    "            eval_dict[input_data_fields.original_image_spatial_shape][indx],\n",
    "            axis=0),\n",
    "        true_image_shape=tf.expand_dims(\n",
    "            eval_dict[input_data_fields.true_image_shape][indx], axis=0),\n",
    "        instance_masks=groundtruth_instance_masks,\n",
    "        keypoints=groundtruth_keypoints,\n",
    "        keypoint_scores=groundtruth_keypoint_scores,\n",
    "        keypoint_edges=keypoint_edges,\n",
    "        max_boxes_to_draw=None,\n",
    "        min_score_thresh=0.0,\n",
    "        use_normalized_coordinates=use_normalized_coordinates)\n",
    "    images_to_visualize = tf.concat([images_with_detections,\n",
    "                                     images_with_groundtruth], axis=2)\n",
    "\n",
    "    if input_data_fields.image_additional_channels in eval_dict:\n",
    "      images_with_additional_channels_groundtruth = (\n",
    "          draw_bounding_boxes_on_image_tensors(\n",
    "              tf.expand_dims(\n",
    "                  eval_dict[input_data_fields.image_additional_channels][indx],\n",
    "                  axis=0),\n",
    "              tf.expand_dims(\n",
    "                  eval_dict[input_data_fields.groundtruth_boxes][indx]\n",
    "                  [:num_gt_boxes_i],\n",
    "                  axis=0),\n",
    "              tf.expand_dims(\n",
    "                  eval_dict[input_data_fields.groundtruth_classes][indx]\n",
    "                  [:num_gt_boxes_i],\n",
    "                  axis=0),\n",
    "              tf.expand_dims(\n",
    "                  tf.ones_like(\n",
    "                      eval_dict[input_data_fields.groundtruth_classes][indx]\n",
    "                      [num_gt_boxes_i],\n",
    "                      dtype=tf.float32),\n",
    "                  axis=0),\n",
    "              category_index,\n",
    "              original_image_spatial_shape=tf.expand_dims(\n",
    "                  eval_dict[input_data_fields.original_image_spatial_shape]\n",
    "                  [indx],\n",
    "                  axis=0),\n",
    "              true_image_shape=tf.expand_dims(\n",
    "                  eval_dict[input_data_fields.true_image_shape][indx], axis=0),\n",
    "              instance_masks=groundtruth_instance_masks,\n",
    "              keypoints=None,\n",
    "              keypoint_edges=None,\n",
    "              max_boxes_to_draw=None,\n",
    "              min_score_thresh=0.0,\n",
    "              use_normalized_coordinates=use_normalized_coordinates))\n",
    "      images_to_visualize = tf.concat(\n",
    "          [images_to_visualize, images_with_additional_channels_groundtruth],\n",
    "          axis=2)\n",
    "    images_with_detections_list.append(images_to_visualize)\n",
    "\n",
    "  return images_with_detections_list\n",
    "\n",
    "\n",
    "def draw_densepose_visualizations(eval_dict,\n",
    "                                  max_boxes_to_draw=20,\n",
    "                                  min_score_thresh=0.2,\n",
    "                                  num_parts=24,\n",
    "                                  dp_coord_to_visualize=0):\n",
    "  \"\"\"Draws DensePose visualizations.\n",
    "  Args:\n",
    "    eval_dict: The evaluation dictionary returned by\n",
    "      eval_util.result_dict_for_batched_example().\n",
    "    max_boxes_to_draw: The maximum number of boxes to draw for detections.\n",
    "    min_score_thresh: The minimum score threshold for showing detections.\n",
    "    num_parts: The number of different densepose parts.\n",
    "    dp_coord_to_visualize: Whether to visualize v-coordinates (0) or\n",
    "      u-coordinates (0) overlaid on the person masks.\n",
    "  Returns:\n",
    "    A list of [1, H, W, C] uint8 tensor, each element corresponding to an image\n",
    "    in the batch.\n",
    "  Raises:\n",
    "    ValueError: If `dp_coord_to_visualize` is not 0 or 1.\n",
    "  \"\"\"\n",
    "  if dp_coord_to_visualize not in (0, 1):\n",
    "    raise ValueError('`dp_coord_to_visualize` must be either 0 for v '\n",
    "                     'coordinates), or 1 for u coordinates, but instead got '\n",
    "                     '{}'.format(dp_coord_to_visualize))\n",
    "  detection_fields = fields.DetectionResultFields()\n",
    "  input_data_fields = fields.InputDataFields()\n",
    "\n",
    "  if detection_fields.detection_masks not in eval_dict:\n",
    "    raise ValueError('Expected `detection_masks` in `eval_dict`.')\n",
    "  if detection_fields.detection_surface_coords not in eval_dict:\n",
    "    raise ValueError('Expected `detection_surface_coords` in `eval_dict`.')\n",
    "\n",
    "  images_with_detections_list = []\n",
    "  for indx in range(eval_dict[input_data_fields.original_image].shape[0]):\n",
    "    # Note that detection masks have already been resized to the original image\n",
    "    # shapes, but `original_image` has not.\n",
    "    # TODO(ronnyvotel): Consider resizing `original_image` in\n",
    "    # eval_util.result_dict_for_batched_example().\n",
    "    true_shape = eval_dict[input_data_fields.true_image_shape][indx]\n",
    "    original_shape = eval_dict[\n",
    "        input_data_fields.original_image_spatial_shape][indx]\n",
    "    image = eval_dict[input_data_fields.original_image][indx]\n",
    "    image = shape_utils.pad_or_clip_nd(image, [true_shape[0], true_shape[1], 3])\n",
    "    image = _resize_original_image(image, original_shape)\n",
    "\n",
    "    scores = eval_dict[detection_fields.detection_scores][indx]\n",
    "    detection_masks = eval_dict[detection_fields.detection_masks][indx]\n",
    "    surface_coords = eval_dict[detection_fields.detection_surface_coords][indx]\n",
    "\n",
    "    def draw_densepose_py_func(image, detection_masks, surface_coords, scores):\n",
    "      \"\"\"Overlays part masks and surface coords on original images.\"\"\"\n",
    "      surface_coord_image = np.copy(image)\n",
    "      for i, (score, surface_coord, mask) in enumerate(\n",
    "          zip(scores, surface_coords, detection_masks)):\n",
    "        if i == max_boxes_to_draw:\n",
    "          break\n",
    "        if score > min_score_thresh:\n",
    "          draw_part_mask_on_image_array(image, mask, num_parts=num_parts)\n",
    "          draw_float_channel_on_image_array(\n",
    "              surface_coord_image, surface_coord[:, :, dp_coord_to_visualize],\n",
    "              mask)\n",
    "      return np.concatenate([image, surface_coord_image], axis=1)\n",
    "\n",
    "    image_with_densepose = tf.py_func(\n",
    "        draw_densepose_py_func,\n",
    "        [image, detection_masks, surface_coords, scores],\n",
    "        tf.uint8)\n",
    "    images_with_detections_list.append(\n",
    "        image_with_densepose[tf.newaxis, :, :, :])\n",
    "  return images_with_detections_list\n",
    "\n",
    "\n",
    "def draw_keypoints_on_image_array(image,\n",
    "                                  keypoints,\n",
    "                                  keypoint_scores=None,\n",
    "                                  min_score_thresh=0.5,\n",
    "                                  color='red',\n",
    "                                  radius=2,\n",
    "                                  use_normalized_coordinates=True,\n",
    "                                  keypoint_edges=None,\n",
    "                                  keypoint_edge_color='green',\n",
    "                                  keypoint_edge_width=2):\n",
    "  \"\"\"Draws keypoints on an image (numpy array).\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "    keypoints: a numpy array with shape [num_keypoints, 2].\n",
    "    keypoint_scores: a numpy array with shape [num_keypoints]. If provided, only\n",
    "      those keypoints with a score above score_threshold will be visualized.\n",
    "    min_score_thresh: A scalar indicating the minimum keypoint score required\n",
    "      for a keypoint to be visualized. Note that keypoint_scores must be\n",
    "      provided for this threshold to take effect.\n",
    "    color: color to draw the keypoints with. Default is red.\n",
    "    radius: keypoint radius. Default value is 2.\n",
    "    use_normalized_coordinates: if True (default), treat keypoint values as\n",
    "      relative to the image.  Otherwise treat them as absolute.\n",
    "    keypoint_edges: A list of tuples with keypoint indices that specify which\n",
    "      keypoints should be connected by an edge, e.g. [(0, 1), (2, 4)] draws\n",
    "      edges from keypoint 0 to 1 and from keypoint 2 to 4.\n",
    "    keypoint_edge_color: color to draw the keypoint edges with. Default is red.\n",
    "    keypoint_edge_width: width of the edges drawn between keypoints. Default\n",
    "      value is 2.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_keypoints_on_image(image_pil,\n",
    "                          keypoints,\n",
    "                          keypoint_scores=keypoint_scores,\n",
    "                          min_score_thresh=min_score_thresh,\n",
    "                          color=color,\n",
    "                          radius=radius,\n",
    "                          use_normalized_coordinates=use_normalized_coordinates,\n",
    "                          keypoint_edges=keypoint_edges,\n",
    "                          keypoint_edge_color=keypoint_edge_color,\n",
    "                          keypoint_edge_width=keypoint_edge_width)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n",
    "\n",
    "def draw_keypoints_on_image(image,\n",
    "                            keypoints,\n",
    "                            keypoint_scores=None,\n",
    "                            min_score_thresh=0.5,\n",
    "                            color='red',\n",
    "                            radius=2,\n",
    "                            use_normalized_coordinates=True,\n",
    "                            keypoint_edges=None,\n",
    "                            keypoint_edge_color='green',\n",
    "                            keypoint_edge_width=2):\n",
    "  \"\"\"Draws keypoints on an image.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    keypoints: a numpy array with shape [num_keypoints, 2].\n",
    "    keypoint_scores: a numpy array with shape [num_keypoints].\n",
    "    min_score_thresh: a score threshold for visualizing keypoints. Only used if\n",
    "      keypoint_scores is provided.\n",
    "    color: color to draw the keypoints with. Default is red.\n",
    "    radius: keypoint radius. Default value is 2.\n",
    "    use_normalized_coordinates: if True (default), treat keypoint values as\n",
    "      relative to the image.  Otherwise treat them as absolute.\n",
    "    keypoint_edges: A list of tuples with keypoint indices that specify which\n",
    "      keypoints should be connected by an edge, e.g. [(0, 1), (2, 4)] draws\n",
    "      edges from keypoint 0 to 1 and from keypoint 2 to 4.\n",
    "    keypoint_edge_color: color to draw the keypoint edges with. Default is red.\n",
    "    keypoint_edge_width: width of the edges drawn between keypoints. Default\n",
    "      value is 2.\n",
    "  \"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  keypoints = np.array(keypoints)\n",
    "  keypoints_x = [k[1] for k in keypoints]\n",
    "  keypoints_y = [k[0] for k in keypoints]\n",
    "  if use_normalized_coordinates:\n",
    "    keypoints_x = tuple([im_width * x for x in keypoints_x])\n",
    "    keypoints_y = tuple([im_height * y for y in keypoints_y])\n",
    "  if keypoint_scores is not None:\n",
    "    keypoint_scores = np.array(keypoint_scores)\n",
    "    valid_kpt = np.greater(keypoint_scores, min_score_thresh)\n",
    "  else:\n",
    "    valid_kpt = np.where(np.any(np.isnan(keypoints), axis=1),\n",
    "                         np.zeros_like(keypoints[:, 0]),\n",
    "                         np.ones_like(keypoints[:, 0]))\n",
    "  valid_kpt = [v for v in valid_kpt]\n",
    "\n",
    "  for keypoint_x, keypoint_y, valid in zip(keypoints_x, keypoints_y, valid_kpt):\n",
    "    if valid:\n",
    "      draw.ellipse([(keypoint_x - radius, keypoint_y - radius),\n",
    "                    (keypoint_x + radius, keypoint_y + radius)],\n",
    "                   outline=color, fill=color)\n",
    "  if keypoint_edges is not None:\n",
    "    for keypoint_start, keypoint_end in keypoint_edges:\n",
    "      if (keypoint_start < 0 or keypoint_start >= len(keypoints) or\n",
    "          keypoint_end < 0 or keypoint_end >= len(keypoints)):\n",
    "        continue\n",
    "      if not (valid_kpt[keypoint_start] and valid_kpt[keypoint_end]):\n",
    "        continue\n",
    "      edge_coordinates = [\n",
    "          keypoints_x[keypoint_start], keypoints_y[keypoint_start],\n",
    "          keypoints_x[keypoint_end], keypoints_y[keypoint_end]\n",
    "      ]\n",
    "      draw.line(\n",
    "          edge_coordinates, fill=keypoint_edge_color, width=keypoint_edge_width)\n",
    "\n",
    "\n",
    "def draw_mask_on_image_array(image, mask, color='red', alpha=0.4):\n",
    "  \"\"\"Draws mask on an image.\n",
    "  Args:\n",
    "    image: uint8 numpy array with shape (img_height, img_height, 3)\n",
    "    mask: a uint8 numpy array of shape (img_height, img_height) with\n",
    "      values between either 0 or 1.\n",
    "    color: color to draw the keypoints with. Default is red.\n",
    "    alpha: transparency value between 0 and 1. (default: 0.4)\n",
    "  Raises:\n",
    "    ValueError: On incorrect data type for image or masks.\n",
    "  \"\"\"\n",
    "  if image.dtype != np.uint8:\n",
    "    raise ValueError('`image` not of type np.uint8')\n",
    "  if mask.dtype != np.uint8:\n",
    "    raise ValueError('`mask` not of type np.uint8')\n",
    "  if image.shape[:2] != mask.shape:\n",
    "    raise ValueError('The image has spatial dimensions %s but the mask has '\n",
    "                     'dimensions %s' % (image.shape[:2], mask.shape))\n",
    "  rgb = ImageColor.getrgb(color)\n",
    "  pil_image = Image.fromarray(image)\n",
    "\n",
    "  solid_color = np.expand_dims(\n",
    "      np.ones_like(mask), axis=2) * np.reshape(list(rgb), [1, 1, 3])\n",
    "  pil_solid_color = Image.fromarray(np.uint8(solid_color)).convert('RGBA')\n",
    "  pil_mask = Image.fromarray(np.uint8(255.0*alpha*(mask > 0))).convert('L')\n",
    "  pil_image = Image.composite(pil_solid_color, pil_image, pil_mask)\n",
    "  np.copyto(image, np.array(pil_image.convert('RGB')))\n",
    "\n",
    "\n",
    "def draw_part_mask_on_image_array(image, mask, alpha=0.4, num_parts=24):\n",
    "  \"\"\"Draws part mask on an image.\n",
    "  Args:\n",
    "    image: uint8 numpy array with shape (img_height, img_height, 3)\n",
    "    mask: a uint8 numpy array of shape (img_height, img_height) with\n",
    "      1-indexed parts (0 for background).\n",
    "    alpha: transparency value between 0 and 1 (default: 0.4)\n",
    "    num_parts: the maximum number of parts that may exist in the image (default\n",
    "      24 for DensePose).\n",
    "  Raises:\n",
    "    ValueError: On incorrect data type for image or masks.\n",
    "  \"\"\"\n",
    "  if image.dtype != np.uint8:\n",
    "    raise ValueError('`image` not of type np.uint8')\n",
    "  if mask.dtype != np.uint8:\n",
    "    raise ValueError('`mask` not of type np.uint8')\n",
    "  if image.shape[:2] != mask.shape:\n",
    "    raise ValueError('The image has spatial dimensions %s but the mask has '\n",
    "                     'dimensions %s' % (image.shape[:2], mask.shape))\n",
    "\n",
    "  pil_image = Image.fromarray(image)\n",
    "  part_colors = np.zeros_like(image)\n",
    "  mask_1_channel = mask[:, :, np.newaxis]\n",
    "  for i, color in enumerate(STANDARD_COLORS[:num_parts]):\n",
    "    rgb = np.array(ImageColor.getrgb(color), dtype=np.uint8)\n",
    "    part_colors += (mask_1_channel == i + 1) * rgb[np.newaxis, np.newaxis, :]\n",
    "  pil_part_colors = Image.fromarray(np.uint8(part_colors)).convert('RGBA')\n",
    "  pil_mask = Image.fromarray(np.uint8(255.0 * alpha * (mask > 0))).convert('L')\n",
    "  pil_image = Image.composite(pil_part_colors, pil_image, pil_mask)\n",
    "  np.copyto(image, np.array(pil_image.convert('RGB')))\n",
    "\n",
    "\n",
    "def draw_float_channel_on_image_array(image, channel, mask, alpha=0.9,\n",
    "                                      cmap='YlGn'):\n",
    "  \"\"\"Draws a floating point channel on an image array.\n",
    "  Args:\n",
    "    image: uint8 numpy array with shape (img_height, img_height, 3)\n",
    "    channel: float32 numpy array with shape (img_height, img_height). The values\n",
    "      should be in the range [0, 1], and will be mapped to colors using the\n",
    "      provided colormap `cmap` argument.\n",
    "    mask: a uint8 numpy array of shape (img_height, img_height) with\n",
    "      1-indexed parts (0 for background).\n",
    "    alpha: transparency value between 0 and 1 (default: 0.9)\n",
    "    cmap: string with the colormap to use.\n",
    "  Raises:\n",
    "    ValueError: On incorrect data type for image or masks.\n",
    "  \"\"\"\n",
    "  if image.dtype != np.uint8:\n",
    "    raise ValueError('`image` not of type np.uint8')\n",
    "  if channel.dtype != np.float32:\n",
    "    raise ValueError('`channel` not of type np.float32')\n",
    "  if mask.dtype != np.uint8:\n",
    "    raise ValueError('`mask` not of type np.uint8')\n",
    "  if image.shape[:2] != channel.shape:\n",
    "    raise ValueError('The image has spatial dimensions %s but the channel has '\n",
    "                     'dimensions %s' % (image.shape[:2], channel.shape))\n",
    "  if image.shape[:2] != mask.shape:\n",
    "    raise ValueError('The image has spatial dimensions %s but the mask has '\n",
    "                     'dimensions %s' % (image.shape[:2], mask.shape))\n",
    "\n",
    "  cm = plt.get_cmap(cmap)\n",
    "  pil_image = Image.fromarray(image)\n",
    "  colored_channel = cm(channel)[:, :, :3]\n",
    "  pil_colored_channel = Image.fromarray(\n",
    "      np.uint8(colored_channel * 255)).convert('RGBA')\n",
    "  pil_mask = Image.fromarray(np.uint8(255.0 * alpha * (mask > 0))).convert('L')\n",
    "  pil_image = Image.composite(pil_colored_channel, pil_image, pil_mask)\n",
    "  np.copyto(image, np.array(pil_image.convert('RGB')))\n",
    "\n",
    "\n",
    "def visualize_boxes_and_labels_on_image_array(\n",
    "    image,\n",
    "    boxes,\n",
    "    classes,\n",
    "    scores,\n",
    "    category_index,\n",
    "    instance_masks=None,\n",
    "    instance_boundaries=None,\n",
    "    keypoints=None,\n",
    "    keypoint_scores=None,\n",
    "    keypoint_edges=None,\n",
    "    track_ids=None,\n",
    "    use_normalized_coordinates=False,\n",
    "    max_boxes_to_draw=20,\n",
    "    min_score_thresh=.5,\n",
    "    agnostic_mode=False,\n",
    "    line_thickness=4,\n",
    "    mask_alpha=.4,\n",
    "    groundtruth_box_visualization_color='black',\n",
    "    skip_boxes=False,\n",
    "    skip_scores=False,\n",
    "    skip_labels=False,\n",
    "    skip_track_ids=False):\n",
    "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\n",
    "  This function groups boxes that correspond to the same location\n",
    "  and creates a display string for each detection and overlays these\n",
    "  on the image. Note that this function modifies the image in place, and returns\n",
    "  that same image.\n",
    "  Args:\n",
    "    image: uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    boxes: a numpy array of shape [N, 4]\n",
    "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
    "      and match the keys in the label map.\n",
    "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
    "      this function assumes that the boxes to be plotted are groundtruth\n",
    "      boxes and plot all boxes as black with no classes or scores.\n",
    "    category_index: a dict containing category dictionaries (each holding\n",
    "      category index `id` and category name `name`) keyed by category indices.\n",
    "    instance_masks: a uint8 numpy array of shape [N, image_height, image_width],\n",
    "      can be None.\n",
    "    instance_boundaries: a numpy array of shape [N, image_height, image_width]\n",
    "      with values ranging between 0 and 1, can be None.\n",
    "    keypoints: a numpy array of shape [N, num_keypoints, 2], can\n",
    "      be None.\n",
    "    keypoint_scores: a numpy array of shape [N, num_keypoints], can be None.\n",
    "    keypoint_edges: A list of tuples with keypoint indices that specify which\n",
    "      keypoints should be connected by an edge, e.g. [(0, 1), (2, 4)] draws\n",
    "      edges from keypoint 0 to 1 and from keypoint 2 to 4.\n",
    "    track_ids: a numpy array of shape [N] with unique track ids. If provided,\n",
    "      color-coding of boxes will be determined by these ids, and not the class\n",
    "      indices.\n",
    "    use_normalized_coordinates: whether boxes is to be interpreted as\n",
    "      normalized coordinates or not.\n",
    "    max_boxes_to_draw: maximum number of boxes to visualize.  If None, draw\n",
    "      all boxes.\n",
    "    min_score_thresh: minimum score threshold for a box or keypoint to be\n",
    "      visualized.\n",
    "    agnostic_mode: boolean (default: False) controlling whether to evaluate in\n",
    "      class-agnostic mode or not.  This mode will display scores but ignore\n",
    "      classes.\n",
    "    line_thickness: integer (default: 4) controlling line width of the boxes.\n",
    "    mask_alpha: transparency value between 0 and 1 (default: 0.4).\n",
    "    groundtruth_box_visualization_color: box color for visualizing groundtruth\n",
    "      boxes\n",
    "    skip_boxes: whether to skip the drawing of bounding boxes.\n",
    "    skip_scores: whether to skip score when drawing a single detection\n",
    "    skip_labels: whether to skip label when drawing a single detection\n",
    "    skip_track_ids: whether to skip track id when drawing a single detection\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3) with overlaid boxes.\n",
    "  \"\"\"\n",
    "  # Create a display string (and color) for every box location, group any boxes\n",
    "  # that correspond to the same location.\n",
    "  final_label=None  \n",
    "  box_to_display_str_map = collections.defaultdict(list)\n",
    "  box_to_color_map = collections.defaultdict(str)\n",
    "  box_to_instance_masks_map = {}\n",
    "  box_to_instance_boundaries_map = {}\n",
    "  box_to_keypoints_map = collections.defaultdict(list)\n",
    "  box_to_keypoint_scores_map = collections.defaultdict(list)\n",
    "  box_to_track_ids_map = {}\n",
    "  if not max_boxes_to_draw:\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    "  for i in range(boxes.shape[0]):\n",
    "    if max_boxes_to_draw == len(box_to_color_map):\n",
    "      break\n",
    "    if scores is None or scores[i] > min_score_thresh:\n",
    "      box = tuple(boxes[i].tolist())\n",
    "      if instance_masks is not None:\n",
    "        box_to_instance_masks_map[box] = instance_masks[i]\n",
    "      if instance_boundaries is not None:\n",
    "        box_to_instance_boundaries_map[box] = instance_boundaries[i]\n",
    "      if keypoints is not None:\n",
    "        box_to_keypoints_map[box].extend(keypoints[i])\n",
    "      if keypoint_scores is not None:\n",
    "        box_to_keypoint_scores_map[box].extend(keypoint_scores[i])\n",
    "      if track_ids is not None:\n",
    "        box_to_track_ids_map[box] = track_ids[i]\n",
    "      if scores is None:\n",
    "        box_to_color_map[box] = groundtruth_box_visualization_color\n",
    "      else:\n",
    "        display_str = ''\n",
    "        if not skip_labels:\n",
    "          if not agnostic_mode:\n",
    "            if classes[i] in six.viewkeys(category_index):\n",
    "              class_name = category_index[classes[i]]['name']\n",
    "            else:\n",
    "              class_name = 'N/A'\n",
    "            display_str = str(class_name)\n",
    "            \n",
    "        final_label = display_str\n",
    "        if not skip_scores:\n",
    "          if not display_str:\n",
    "            display_str = '{}%'.format(round(100*scores[i]))\n",
    "            final_label = display_str\n",
    "          else:\n",
    "            display_str = '{}: {}%'.format(display_str, round(100*scores[i]))\n",
    "        if not skip_track_ids and track_ids is not None:\n",
    "          if not display_str:\n",
    "            display_str = 'ID {}'.format(track_ids[i])\n",
    "            final_label = track_ids[i]\n",
    "          else:\n",
    "            display_str = '{}: ID {}'.format(display_str, track_ids[i])\n",
    "        \n",
    "        box_to_display_str_map[box].append(display_str)\n",
    "        if agnostic_mode:\n",
    "          box_to_color_map[box] = 'DarkOrange'\n",
    "        elif track_ids is not None:\n",
    "          prime_multipler = _get_multiplier_for_color_randomness()\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              (prime_multipler * track_ids[i]) % len(STANDARD_COLORS)]\n",
    "        else:\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              classes[i] % len(STANDARD_COLORS)]\n",
    "\n",
    "  # Draw all boxes onto image.\n",
    "  for box, color in box_to_color_map.items():\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    if instance_masks is not None:\n",
    "      draw_mask_on_image_array(\n",
    "          image,\n",
    "          box_to_instance_masks_map[box],\n",
    "          color=color,\n",
    "          alpha=mask_alpha\n",
    "      )\n",
    "    if instance_boundaries is not None:\n",
    "      draw_mask_on_image_array(\n",
    "          image,\n",
    "          box_to_instance_boundaries_map[box],\n",
    "          color='red',\n",
    "          alpha=1.0\n",
    "      )\n",
    "    draw_bounding_box_on_image_array(\n",
    "        image,\n",
    "        ymin,\n",
    "        xmin,\n",
    "        ymax,\n",
    "        xmax,\n",
    "        color=color,\n",
    "        thickness=0 if skip_boxes else line_thickness,\n",
    "        display_str_list=box_to_display_str_map[box],\n",
    "        use_normalized_coordinates=use_normalized_coordinates)\n",
    "    if keypoints is not None:\n",
    "      keypoint_scores_for_box = None\n",
    "      if box_to_keypoint_scores_map:\n",
    "        keypoint_scores_for_box = box_to_keypoint_scores_map[box]\n",
    "      draw_keypoints_on_image_array(\n",
    "          image,\n",
    "          box_to_keypoints_map[box],\n",
    "          keypoint_scores_for_box,\n",
    "          min_score_thresh=min_score_thresh,\n",
    "          color=color,\n",
    "          radius=line_thickness / 2,\n",
    "          use_normalized_coordinates=use_normalized_coordinates,\n",
    "          keypoint_edges=keypoint_edges,\n",
    "          keypoint_edge_color=color,\n",
    "          keypoint_edge_width=line_thickness // 2)\n",
    "  if final_label==None:\n",
    "      return \"0\", image\n",
    "  return final_label, image\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "def add_cdf_image_summary(values, name):\n",
    "  \"\"\"Adds a tf.summary.image for a CDF plot of the values.\n",
    "  Normalizes `values` such that they sum to 1, plots the cumulative distribution\n",
    "  function and creates a tf image summary.\n",
    "  Args:\n",
    "    values: a 1-D float32 tensor containing the values.\n",
    "    name: name for the image summary.\n",
    "  \"\"\"\n",
    "  def cdf_plot(values):\n",
    "    \"\"\"Numpy function to plot CDF.\"\"\"\n",
    "    normalized_values = values / np.sum(values)\n",
    "    sorted_values = np.sort(normalized_values)\n",
    "    cumulative_values = np.cumsum(sorted_values)\n",
    "    fraction_of_examples = (np.arange(cumulative_values.size, dtype=np.float32)\n",
    "                            / cumulative_values.size)\n",
    "    fig = plt.figure(frameon=False)\n",
    "    ax = fig.add_subplot('111')\n",
    "    ax.plot(fraction_of_examples, cumulative_values)\n",
    "    ax.set_ylabel('cumulative normalized values')\n",
    "    ax.set_xlabel('fraction of examples')\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "    image = np.fromstring(fig.canvas.tostring_rgb(), dtype='uint8').reshape(\n",
    "        1, int(height), int(width), 3)\n",
    "    return image\n",
    "  cdf_plot = tf.py_func(cdf_plot, [values], tf.uint8)\n",
    "  tf.summary.image(name, cdf_plot)\n",
    "\n",
    "\n",
    "def add_hist_image_summary(values, bins, name):\n",
    "  \"\"\"Adds a tf.summary.image for a histogram plot of the values.\n",
    "  Plots the histogram of values and creates a tf image summary.\n",
    "  Args:\n",
    "    values: a 1-D float32 tensor containing the values.\n",
    "    bins: bin edges which will be directly passed to np.histogram.\n",
    "    name: name for the image summary.\n",
    "  \"\"\"\n",
    "\n",
    "  def hist_plot(values, bins):\n",
    "    \"\"\"Numpy function to plot hist.\"\"\"\n",
    "    fig = plt.figure(frameon=False)\n",
    "    ax = fig.add_subplot('111')\n",
    "    y, x = np.histogram(values, bins=bins)\n",
    "    ax.plot(x[:-1], y)\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xlabel('value')\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "    image = np.fromstring(\n",
    "        fig.canvas.tostring_rgb(), dtype='uint8').reshape(\n",
    "            1, int(height), int(width), 3)\n",
    "    return image\n",
    "  hist_plot = tf.py_func(hist_plot, [values, bins], tf.uint8)\n",
    "  tf.summary.image(name, hist_plot)\n",
    "\n",
    "\n",
    "class EvalMetricOpsVisualization(six.with_metaclass(abc.ABCMeta, object)):\n",
    "  \"\"\"Abstract base class responsible for visualizations during evaluation.\n",
    "  Currently, summary images are not run during evaluation. One way to produce\n",
    "  evaluation images in Tensorboard is to provide tf.summary.image strings as\n",
    "  `value_ops` in tf.estimator.EstimatorSpec's `eval_metric_ops`. This class is\n",
    "  responsible for accruing images (with overlaid detections and groundtruth)\n",
    "  and returning a dictionary that can be passed to `eval_metric_ops`.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               category_index,\n",
    "               max_examples_to_draw=5,\n",
    "               max_boxes_to_draw=20,\n",
    "               min_score_thresh=0.2,\n",
    "               use_normalized_coordinates=True,\n",
    "               summary_name_prefix='evaluation_image',\n",
    "               keypoint_edges=None):\n",
    "    \"\"\"Creates an EvalMetricOpsVisualization.\n",
    "    Args:\n",
    "      category_index: A category index (dictionary) produced from a labelmap.\n",
    "      max_examples_to_draw: The maximum number of example summaries to produce.\n",
    "      max_boxes_to_draw: The maximum number of boxes to draw for detections.\n",
    "      min_score_thresh: The minimum score threshold for showing detections.\n",
    "      use_normalized_coordinates: Whether to assume boxes and keypoints are in\n",
    "        normalized coordinates (as opposed to absolute coordinates).\n",
    "        Default is True.\n",
    "      summary_name_prefix: A string prefix for each image summary.\n",
    "      keypoint_edges: A list of tuples with keypoint indices that specify which\n",
    "        keypoints should be connected by an edge, e.g. [(0, 1), (2, 4)] draws\n",
    "        edges from keypoint 0 to 1 and from keypoint 2 to 4.\n",
    "    \"\"\"\n",
    "\n",
    "    self._category_index = category_index\n",
    "    self._max_examples_to_draw = max_examples_to_draw\n",
    "    self._max_boxes_to_draw = max_boxes_to_draw\n",
    "    self._min_score_thresh = min_score_thresh\n",
    "    self._use_normalized_coordinates = use_normalized_coordinates\n",
    "    self._summary_name_prefix = summary_name_prefix\n",
    "    self._keypoint_edges = keypoint_edges\n",
    "    self._images = []\n",
    "\n",
    "  def clear(self):\n",
    "    self._images = []\n",
    "\n",
    "  def add_images(self, images):\n",
    "    \"\"\"Store a list of images, each with shape [1, H, W, C].\"\"\"\n",
    "    if len(self._images) >= self._max_examples_to_draw:\n",
    "      return\n",
    "\n",
    "    # Store images and clip list if necessary.\n",
    "    self._images.extend(images)\n",
    "    if len(self._images) > self._max_examples_to_draw:\n",
    "      self._images[self._max_examples_to_draw:] = []\n",
    "\n",
    "  def get_estimator_eval_metric_ops(self, eval_dict):\n",
    "    \"\"\"Returns metric ops for use in tf.estimator.EstimatorSpec.\n",
    "    Args:\n",
    "      eval_dict: A dictionary that holds an image, groundtruth, and detections\n",
    "        for a batched example. Note that, we use only the first example for\n",
    "        visualization. See eval_util.result_dict_for_batched_example() for a\n",
    "        convenient method for constructing such a dictionary. The dictionary\n",
    "        contains\n",
    "        fields.InputDataFields.original_image: [batch_size, H, W, 3] image.\n",
    "        fields.InputDataFields.original_image_spatial_shape: [batch_size, 2]\n",
    "          tensor containing the size of the original image.\n",
    "        fields.InputDataFields.true_image_shape: [batch_size, 3]\n",
    "          tensor containing the spatial size of the upadded original image.\n",
    "        fields.InputDataFields.groundtruth_boxes - [batch_size, num_boxes, 4]\n",
    "          float32 tensor with groundtruth boxes in range [0.0, 1.0].\n",
    "        fields.InputDataFields.groundtruth_classes - [batch_size, num_boxes]\n",
    "          int64 tensor with 1-indexed groundtruth classes.\n",
    "        fields.InputDataFields.groundtruth_instance_masks - (optional)\n",
    "          [batch_size, num_boxes, H, W] int64 tensor with instance masks.\n",
    "        fields.InputDataFields.groundtruth_keypoints - (optional)\n",
    "          [batch_size, num_boxes, num_keypoints, 2] float32 tensor with\n",
    "          keypoint coordinates in format [y, x].\n",
    "        fields.InputDataFields.groundtruth_keypoint_visibilities - (optional)\n",
    "          [batch_size, num_boxes, num_keypoints] bool tensor with\n",
    "          keypoint visibilities.\n",
    "        fields.DetectionResultFields.detection_boxes - [batch_size,\n",
    "          max_num_boxes, 4] float32 tensor with detection boxes in range [0.0,\n",
    "          1.0].\n",
    "        fields.DetectionResultFields.detection_classes - [batch_size,\n",
    "          max_num_boxes] int64 tensor with 1-indexed detection classes.\n",
    "        fields.DetectionResultFields.detection_scores - [batch_size,\n",
    "          max_num_boxes] float32 tensor with detection scores.\n",
    "        fields.DetectionResultFields.detection_masks - (optional) [batch_size,\n",
    "          max_num_boxes, H, W] float32 tensor of binarized masks.\n",
    "        fields.DetectionResultFields.detection_keypoints - (optional)\n",
    "          [batch_size, max_num_boxes, num_keypoints, 2] float32 tensor with\n",
    "          keypoints.\n",
    "        fields.DetectionResultFields.detection_keypoint_scores - (optional)\n",
    "          [batch_size, max_num_boxes, num_keypoints] float32 tensor with\n",
    "          keypoints scores.\n",
    "    Returns:\n",
    "      A dictionary of image summary names to tuple of (value_op, update_op). The\n",
    "      `update_op` is the same for all items in the dictionary, and is\n",
    "      responsible for saving a single side-by-side image with detections and\n",
    "      groundtruth. Each `value_op` holds the tf.summary.image string for a given\n",
    "      image.\n",
    "    \"\"\"\n",
    "    if self._max_examples_to_draw == 0:\n",
    "      return {}\n",
    "    images = self.images_from_evaluation_dict(eval_dict)\n",
    "\n",
    "    def get_images():\n",
    "      \"\"\"Returns a list of images, padded to self._max_images_to_draw.\"\"\"\n",
    "      images = self._images\n",
    "      while len(images) < self._max_examples_to_draw:\n",
    "        images.append(np.array(0, dtype=np.uint8))\n",
    "      self.clear()\n",
    "      return images\n",
    "\n",
    "    def image_summary_or_default_string(summary_name, image):\n",
    "      \"\"\"Returns image summaries for non-padded elements.\"\"\"\n",
    "      return tf.cond(\n",
    "          tf.equal(tf.size(tf.shape(image)), 4),\n",
    "          lambda: tf.summary.image(summary_name, image),\n",
    "          lambda: tf.constant(''))\n",
    "\n",
    "    if tf.executing_eagerly():\n",
    "      update_op = self.add_images([[images[0]]])\n",
    "      image_tensors = get_images()\n",
    "    else:\n",
    "      update_op = tf.py_func(self.add_images, [[images[0]]], [])\n",
    "      image_tensors = tf.py_func(\n",
    "          get_images, [], [tf.uint8] * self._max_examples_to_draw)\n",
    "    eval_metric_ops = {}\n",
    "    for i, image in enumerate(image_tensors):\n",
    "      summary_name = self._summary_name_prefix + '/' + str(i)\n",
    "      value_op = image_summary_or_default_string(summary_name, image)\n",
    "      eval_metric_ops[summary_name] = (value_op, update_op)\n",
    "    return eval_metric_ops\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def images_from_evaluation_dict(self, eval_dict):\n",
    "    \"\"\"Converts evaluation dictionary into a list of image tensors.\n",
    "    To be overridden by implementations.\n",
    "    Args:\n",
    "      eval_dict: A dictionary with all the necessary information for producing\n",
    "        visualizations.\n",
    "    Returns:\n",
    "      A list of [1, H, W, C] uint8 tensors.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "class VisualizeSingleFrameDetections(EvalMetricOpsVisualization):\n",
    "  \"\"\"Class responsible for single-frame object detection visualizations.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               category_index,\n",
    "               max_examples_to_draw=5,\n",
    "               max_boxes_to_draw=20,\n",
    "               min_score_thresh=0.2,\n",
    "               use_normalized_coordinates=True,\n",
    "               summary_name_prefix='Detections_Left_Groundtruth_Right',\n",
    "               keypoint_edges=None):\n",
    "    super(VisualizeSingleFrameDetections, self).__init__(\n",
    "        category_index=category_index,\n",
    "        max_examples_to_draw=max_examples_to_draw,\n",
    "        max_boxes_to_draw=max_boxes_to_draw,\n",
    "        min_score_thresh=min_score_thresh,\n",
    "        use_normalized_coordinates=use_normalized_coordinates,\n",
    "        summary_name_prefix=summary_name_prefix,\n",
    "        keypoint_edges=keypoint_edges)\n",
    "\n",
    "  def images_from_evaluation_dict(self, eval_dict):\n",
    "    return draw_side_by_side_evaluation_image(eval_dict, self._category_index,\n",
    "                                              self._max_boxes_to_draw,\n",
    "                                              self._min_score_thresh,\n",
    "                                              self._use_normalized_coordinates,\n",
    "                                              self._keypoint_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_label=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "f = open(\"myfile.txt\", \"w\")  \n",
    "  \n",
    "# define a video capture object\n",
    "\n",
    "cap= cv2.VideoCapture(0)  \n",
    "while True:\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image_np = np.array(frame)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    \n",
    "    label,_=visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=1,\n",
    "                min_score_thresh=.5,\n",
    "                agnostic_mode=False)\n",
    "    if label!=\"0\":\n",
    "        f.write(label)\n",
    "    \n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        f.close()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=['HI','HOW','TEAM','PROJECT','SPEED','FLY','WEB','CONSOLE','LAPTOP','PEN','BOX','BENCH','CONTROL','REMOTE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"myfile.txt\", \"r\")\n",
    "s=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBBBBBBBBBBBBMMMMOOOOOOOOOMXXXXXXXXXXXXXXXXXXXXXXXXX\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "co=1\n",
    "prev=s[0]\n",
    "ans=''\n",
    "for i in s:\n",
    "  if(i!=prev):\n",
    "    if(co>=5):\n",
    "      ans+=prev\n",
    "    prev=i\n",
    "    co=1\n",
    "  else:\n",
    "    co+=1\n",
    "if(co>=10):\n",
    "  ans+=prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOX'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOX']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import difflib\n",
    "difflib.get_close_matches(ans,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
